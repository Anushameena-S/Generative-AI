{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-23T13:09:50.058353Z",
     "iopub.status.busy": "2025-01-23T13:09:50.058075Z",
     "iopub.status.idle": "2025-01-23T13:09:57.410180Z",
     "shell.execute_reply": "2025-01-23T13:09:57.408764Z",
     "shell.execute_reply.started": "2025-01-23T13:09:50.058327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.12.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.57.4\n",
      "    Uninstalling openai-1.57.4:\n",
      "      Successfully uninstalled openai-1.57.4\n",
      "Successfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:09:57.411742Z",
     "iopub.status.busy": "2025-01-23T13:09:57.411360Z",
     "iopub.status.idle": "2025-01-23T13:09:57.926248Z",
     "shell.execute_reply": "2025-01-23T13:09:57.925098Z",
     "shell.execute_reply.started": "2025-01-23T13:09:57.411711Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:09:57.927561Z",
     "iopub.status.busy": "2025-01-23T13:09:57.927153Z",
     "iopub.status.idle": "2025-01-23T13:09:57.931866Z",
     "shell.execute_reply": "2025-01-23T13:09:57.930801Z",
     "shell.execute_reply.started": "2025-01-23T13:09:57.927525Z"
    }
   },
   "outputs": [],
   "source": [
    "api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:17:28.253503Z",
     "iopub.status.busy": "2025-01-23T13:17:28.253058Z",
     "iopub.status.idle": "2025-01-23T13:17:28.260450Z",
     "shell.execute_reply": "2025-01-23T13:17:28.258863Z",
     "shell.execute_reply.started": "2025-01-23T13:17:28.253475Z"
    }
   },
   "outputs": [],
   "source": [
    "def chain_of_thought_completion(prompt, chat_history = []):\n",
    "    messages = [{'role':'user', 'content': msg} for prompt in chat_history]\n",
    "    messages.append({'role':'user','content': prompt})\n",
    "    \n",
    "    # generate a response from model\n",
    "    response = openai.ChatCompletion.create(\n",
    "        api_key = api_key,\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = messages,\n",
    "        max_tokens = 1000,        # Maximum number of tokens\n",
    "        temperature = 1.0,        # Controls randomness in the output (0.0 to 2.0), temp closer to 0.0 model will generate repetitive o/p\n",
    "        top_p = 0.9,              # Nucleus Sampling\n",
    "        presence_penalty = 0.5,   # Penalizes new tokens based on wheather they appear in the text so far.\n",
    "        frequency_penalty = 0.5   # Penalizes new tokens based on their frequency in the text so far\n",
    "    )\n",
    "    model_reply = response['choices'][0]['message']['content']\n",
    "    return model_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. COT Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:23:12.059468Z",
     "iopub.status.busy": "2025-01-23T13:23:12.058936Z",
     "iopub.status.idle": "2025-01-23T13:23:12.065014Z",
     "shell.execute_reply": "2025-01-23T13:23:12.063447Z",
     "shell.execute_reply.started": "2025-01-23T13:23:12.059426Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Imagine you are detective trying to solve a mystery case. You arrive at the crime scene and start looking for clues.\",\n",
    "    \"You find a strange object at the crime scene. What you have found ?\",\n",
    "    \"Link this object to the crime scene and establish a relation with crime.\",\n",
    "    \"Look, for more clues and who do you think is prime suspect of crime and why?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:23:15.518110Z",
     "iopub.status.busy": "2025-01-23T13:23:15.517611Z",
     "iopub.status.idle": "2025-01-23T13:23:22.857737Z",
     "shell.execute_reply": "2025-01-23T13:23:22.856189Z",
     "shell.execute_reply.started": "2025-01-23T13:23:15.518073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Imagine you are detective trying to solve a mystery case. You arrive at the crime scene and start looking for clues.\n",
      "Response: As I arrive at the crime scene, I immediately begin scanning the area for any potential clues. The scene is chaotic, with police officers and forensic investigators already present, but I know that I need to focus on finding any piece of evidence that could lead me closer to solving this mystery.\n",
      "\n",
      "I start by examining the victim's body, looking for any signs of struggle or injuries that could give me a clue as to what happened. As I inspect the surroundings, I notice a broken window nearby and a trail of blood leading away from the scene.\n",
      "\n",
      "I take note of these observations and move on to search for more evidence. I carefully look around for any personal belongings left behind by the victim or potential suspects. A torn piece of fabric catches my eye, and upon closer inspection, I realize it matches the fabric of the victim's shirt.\n",
      "\n",
      "My heart races as pieces of the puzzle start coming together in my mind. Could this torn fabric be from a struggle between the victim and their attacker? And what about the broken window and blood trail?\n",
      "\n",
      "I continue my search, meticulously examining every inch of the crime scene for more clues. Suddenly, a glint catches my eye – a small necklace lying on the ground near where the victim was found. It's delicate and intricately designed, definitely not something that would belong to the victim.\n",
      "\n",
      "With a newfound determination, I carefully bag up all these clues and rush back to my office to analyze them further. As I lay out each piece of evidence before me, a sense of clarity washes over me – I'm one step closer to solving this mystery.\n",
      "\n",
      "With renewed focus and determination, I set out to piece together all these clues and bring justice to those involved in this crime. The mystery may be complex, but with perseverance and keen detective skills, I am confident that no stone will be left unturned in unraveling the truth behind this case.\n",
      "\n",
      "Prompt: You find a strange object at the crime scene. What you have found ?\n",
      "Response: A small metallic device that appears to be some sort of advanced surveillance technology.\n",
      "\n",
      "Prompt: Link this object to the crime scene and establish a relation with crime.\n",
      "Response: Object: A broken window\n",
      "\n",
      "Relation to crime scene: The broken window was found at the crime scene, indicating a possible point of entry for the perpetrator.\n",
      "\n",
      "Established relation with crime: The broken window suggests that someone may have forcibly entered the premises, potentially committing burglary or vandalism. This evidence could help investigators determine how the perpetrator gained access to the crime scene and provide insight into their methods and motives.\n",
      "\n",
      "Prompt: Look, for more clues and who do you think is prime suspect of crime and why?\n",
      "Response: To determine the prime suspect of a crime, investigators typically look for evidence such as motive, opportunity, means, and alibi. They also consider witness statements, physical evidence, and any previous criminal history.\n",
      "\n",
      "Without more information about the specific crime in question, it is difficult to pinpoint a prime suspect. However, some potential factors that could make someone a prime suspect include having a known motive for committing the crime, being in the vicinity at the time of the incident with no credible alibi, or having a history of violent behavior.\n",
      "\n",
      "It is important to remember that assumptions should not be made without concrete evidence linking someone to the crime. The investigation process is crucial in determining guilt or innocence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "    response = chain_of_thought_completion(prompt)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Zero Shot COT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:30:45.670108Z",
     "iopub.status.busy": "2025-01-23T13:30:45.669597Z",
     "iopub.status.idle": "2025-01-23T13:30:45.676087Z",
     "shell.execute_reply": "2025-01-23T13:30:45.674433Z",
     "shell.execute_reply.started": "2025-01-23T13:30:45.670073Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"A bakery shop sells cookies for $1.50 each and muffins for $3.75 each. If a customer buys 3 cookies and 5 muffins. \\\n",
    "Calculate total bill to customer step by step.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:30:54.506048Z",
     "iopub.status.busy": "2025-01-23T13:30:54.505556Z",
     "iopub.status.idle": "2025-01-23T13:30:55.689694Z",
     "shell.execute_reply": "2025-01-23T13:30:55.688535Z",
     "shell.execute_reply.started": "2025-01-23T13:30:54.506010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Calculate the total cost of the cookies\n",
      "3 cookies * $1.50 = $4.50\n",
      "\n",
      "Step 2: Calculate the total cost of the muffins\n",
      "5 muffins * $3.75 = $18.75\n",
      "\n",
      "Step 3: Add the total cost of the cookies and muffins together\n",
      "$4.50 + $18.75 = $23.25\n",
      "\n",
      "Therefore, the total bill to the customer would be $23.25\n"
     ]
    }
   ],
   "source": [
    "print(chain_of_thought_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3, COT for coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:42:48.089548Z",
     "iopub.status.busy": "2025-01-23T13:42:48.089071Z",
     "iopub.status.idle": "2025-01-23T13:42:48.095743Z",
     "shell.execute_reply": "2025-01-23T13:42:48.093966Z",
     "shell.execute_reply.started": "2025-01-23T13:42:48.089516Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Please write a python code that declare a function sorting list of integers using bubble sort.\n",
    "This step by step strictly following the instruction about structure given below.\n",
    "Instructions:\n",
    "1. Given a list as an input, get its length and store it in variable.\n",
    "2. In the loop from the first to the penultimate element of the list, comapre the current integer value with its next neighbour.\n",
    "3. If the neighbour is less tha current element, swap them.\n",
    "4. Else, do nothing and proceed to next element.\n",
    "5. Repeat until loop ends.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:45:17.699491Z",
     "iopub.status.busy": "2025-01-23T13:45:17.698917Z",
     "iopub.status.idle": "2025-01-23T13:45:19.220175Z",
     "shell.execute_reply": "2025-01-23T13:45:19.218669Z",
     "shell.execute_reply.started": "2025-01-23T13:45:17.699446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def bubble_sort(arr):\n",
      "    n = len(arr)\n",
      "    \n",
      "    for i in range(n-1):\n",
      "        for j in range(0, n-i-1):\n",
      "            if arr[j] > arr[j+1]:\n",
      "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
      "    \n",
      "    return arr\n",
      "\n",
      "# Example usage\n",
      "arr = [64, 34, 25, 12, 22, 11, 90]\n",
      "sorted_arr = bubble_sort(arr)\n",
      "print(\"Sorted array:\", sorted_arr)\n"
     ]
    }
   ],
   "source": [
    "print(chain_of_thought_completion(prompt))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
